ï¿¼
<!-- ![image](https://github.com/julianofhernandez/Trash-Sorting/assets/39971693/27b97de6-c49f-4a99-8e29-f9d85d636a0c) -->


## Introduction:

The motive of this project is to utilize any technology available to improve categorization on bank transactions. I believe the categorization which major bank provides is not as detailed and when graphing spending trend, it will obscure the graph, if the ground is not set correctly. This project is solely for personal use to learn ML and statistical analysis. 

## Methods:

Method 1. Use scikit learn with MultinomilaNB to predict. The data given is from credit card statement which comes with already given categories. Not viable option, but want to improve on it. 

Method 2. Use LLM to predict the categories. TODO

<!-- ## Installation

### Python 

Python Version 3.9 available at https://www.python.org/downloads/release/python-390/. Then run ```python3 -m pip install -r requirements.txt```

OR

Conda: install Anaconda, create an environment `conda create --name trashsorting`, activate environment `conda activate trashsorting`, install requirements `pip install -r requirements.txt`

For GPU torch, instead of installing torch in requirements.txt do the below:

Windows/Linux: `conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia`

### NodeJS 

Download and install the latest version of Node.js from the official website: https://nodejs.org/en/download/. Follow the installation instructions for your operating system.

### Yarn

Once NPM is installed with NodeJS you can run
```npm install --global yarn```

## How to run the server

Change to react-website directory and run following commands:
```cd project\front-end_apps\website\react-website\```

1. `yarn install` (may also need to run `yarn add tabler-react tabler-icons-react`)

2. `yarn build` generates a build folder in the current directory

2. `yarn start` to run on http://localhost:3000/

3. start model_inference_app.py in separate terminal to test submitting images


## Testing
#### Front End
```
cd project/front-end-apps
pytest
```
![image](https://user-images.githubusercontent.com/47340315/235586207-a89e2338-49ca-4b29-a3f1-da1273373592.png)

```
cd project\front-end_apps\website\react-website
yarn test
```

![image](https://user-images.githubusercontent.com/39971693/232924965-5f8c446e-5adc-4520-b1f3-067fbd0cf3db.png)


#### Backend
```
cd project/backend/annotation_database
pytest
```

![image](https://user-images.githubusercontent.com/47340315/235585828-c5991630-7889-47c0-8fba-3b12884d8e86.png)


```
cd project/backend/model_inference
pytest
```

![image](https://user-images.githubusercontent.com/47340315/235586790-cc21b96c-d91a-4dcf-9b70-18b50042c3ad.png)


## Development Instructions

### Environment
We recommend using Anaconda to create a Python environment with all the requirements outlined in the requirements.txt file. If you're not familiar with Anaconda, please see the official website or refer to this cheat sheet for the proper commands.

### Code Editor
We recommend using Visual Studio Code (VS Code) with the Python Language and running Jupyter Notebook for this project.

### OS/System Independent
The front-end and backend work on Windows, Mac, and Linux operating systems. However, to run the backend smoothly, we recommend your system to have at least 8GB of RAM and for fast response, a Nvidia GPU with at least 8GB of VRAM.

Please make sure that your system meets these requirements before proceeding with the setup. -->
